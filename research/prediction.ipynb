{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from UNetRMultiClass import logger\n",
    "import cv2\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Machine Learning Projects\\\\Unet-R Full-stack\\\\ML_model'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionPipeline:\n",
    "    def __init__(self,filename=\"testing\"):\n",
    "        self.filename = filename\n",
    "        self.rgb_codes = [\n",
    "        [0, 0, 0], [0, 153, 255], [102, 255, 153], [0, 204, 153],\n",
    "        [255, 255, 102], [255, 255, 204], [255, 153, 0], [255, 102, 255],\n",
    "        [102, 0, 51], [255, 204, 255], [255, 0, 102]\n",
    "        ]\n",
    "\n",
    "        self.classes  = [\n",
    "        \"background\", \"skin\", \"left eyebrow\", \"right eyebrow\",\n",
    "        \"left eye\", \"right eye\", \"nose\", \"upper lip\", \"inner mouth\",\n",
    "        \"lower lip\", \"hair\"\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def grayscale_to_rgb(self, mask, rgb_codes):\n",
    "        h, w = mask.shape[0], mask.shape[1]\n",
    "        mask = mask.astype(np.int32)\n",
    "        output = []\n",
    "        \n",
    "        enum = enumerate(mask.flatten())\n",
    "        \n",
    "        for i, pixel in enum:\n",
    "            output.append(rgb_codes[pixel])\n",
    "\n",
    "        output = np.reshape(output, (h, w, 3))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def save_results(self, image_x, pred, save_image_path):\n",
    "\n",
    "        pred = np.expand_dims(pred, axis=-1)\n",
    "        pred = self.grayscale_to_rgb(pred, self.rgb_codes)\n",
    "\n",
    "        line = np.ones((image_x.shape[0], 10, 3)) * 255\n",
    "\n",
    "        cat_images = np.concatenate([image_x, line, pred], axis=1)\n",
    "        \n",
    "        cv2.imwrite(save_image_path, cat_images)\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self):\n",
    "        cf = {}\n",
    "        cf[\"image_size\"] = 256\n",
    "        cf[\"num_classes\"] = 11\n",
    "        cf[\"num_channels\"] = 3\n",
    "        cf[\"num_layers\"] = 12\n",
    "        cf[\"hidden_dim\"] = 128\n",
    "        cf[\"mlp_dim\"] = 32\n",
    "        cf[\"num_heads\"] = 6\n",
    "        cf[\"dropout_rate\"] = 0.1\n",
    "        cf[\"patch_size\"] = 16\n",
    "        cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "        cf[\"flat_patches_shape\"] = (\n",
    "            cf[\"num_patches\"],\n",
    "            cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    "        )\n",
    "        \n",
    "        onnx_model_path = \"artifacts/training/compatible_model.onnx\"\n",
    "        print(\"model_path: \", onnx_model_path)\n",
    "        o_model = onnx.load(onnx_model_path)\n",
    "        session = ort.InferenceSession(onnx_model_path)\n",
    "        input_name = session.get_inputs()[0].name\n",
    "\n",
    "        \n",
    "        image_name = self.filename\n",
    "        display_name = image_name.split('/')[-1].split('.')[0]\n",
    "        logger.info(f\"input_image name is: {display_name}\")\n",
    "\n",
    "        input_img = cv2.imread(image_name, cv2.IMREAD_COLOR)\n",
    "        input_img = cv2.resize(input_img, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "        norm_input_img = input_img / 255.0\n",
    "\n",
    "        patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "        patches = patchify(norm_input_img, patch_shape, cf[\"patch_size\"])\n",
    "        patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "        patches = patches.astype(np.float32) #[...]\n",
    "        patches = np.expand_dims(patches, axis=0) # [1, ...]\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "\n",
    "        input_dict = {input_name: patches}\n",
    "        output_name = session.get_outputs()[0].name\n",
    "        \n",
    "        outputs = session.run([output_name], input_dict)\n",
    "        pred_1 = np.argmax(outputs, axis=-1) ## [0.1, 0.2, 0.1, 0.6] -> 3\n",
    "        pred_1 = pred_1.astype(np.int32)\n",
    "        pred_1 = np.reshape(pred_1, (256, 256))\n",
    "        \n",
    "        save_image_path = f\"outputs/predict/{display_name}.png\"\n",
    "        self.save_results(input_img, pred_1, save_image_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path:  artifacts/training/compatible_model.onnx\n",
      "[2024-05-07 20:16:38,623: INFO: 411376372: input_image name is: 2569520_1]\n"
     ]
    }
   ],
   "source": [
    "# fname = os.path.join(\"artifacts\", \"LaPa\", \"test\", \"images\", \"2569520_1.jpg\")\n",
    "fname = f\"artifacts/LaPa/test/images/2569520_1.jpg\"\n",
    "pred = PredictionPipeline(filename=fname)\n",
    "pred.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
