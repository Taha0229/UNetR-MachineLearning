{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareModelConfig:\n",
    "    root_dir: Path\n",
    "    model_path: Path\n",
    "    \n",
    "    params_image_size: int\n",
    "    params_num_classes: int\n",
    "    params_num_layers: int\n",
    "    params_hidden_dim: int\n",
    "    params_mlp_dim: int\n",
    "    params_num_heads: int\n",
    "    params_dropout_rate: float\n",
    "    params_num_patches: int\n",
    "    params_patch_size: int\n",
    "    params_num_channels: int\n",
    "    params_learning_rate: float\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "from UNetRMultiClass.constants import *\n",
    "from UNetRMultiClass.utils.common import read_yaml, create_directories\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        self.params.LITE_NUM_PATCHES = (self.params.LITE_IMAGE_SIZE**2)//(self.params.LITE_PATCH_SIZE**2)\n",
    "        self.params.FULL_NUM_PATCHES = (self.params.FULL_IMAGE_SIZE**2)//(self.params.FULL_PATCH_SIZE**2)\n",
    "        ## altering the num_patches because the YAML outputs the string instead of the expression\n",
    "        \n",
    "        \n",
    "    def get_prepare_full_model_config(self) -> PrepareModelConfig:\n",
    "        config = self.config.prepare_models\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_full_model_config = PrepareModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_path=Path(config.full_model_path),\n",
    "            params_image_size=self.params.FULL_IMAGE_SIZE,\n",
    "            params_num_classes=self.params.NUM_CLASSES,\n",
    "            params_num_layers=self.params.FULL_NUM_LAYERS,\n",
    "            params_hidden_dim=self.params.FULL_HIDDEN_DIM,\n",
    "            params_mlp_dim=self.params.FULL_MLP_DIM,\n",
    "            params_num_heads=self.params.FULL_NUM_HEADS,\n",
    "            params_dropout_rate=self.params.DROPOUT_RATE,\n",
    "            params_num_patches=self.params.FULL_NUM_PATCHES,\n",
    "            params_patch_size=self.params.FULL_PATCH_SIZE,\n",
    "            params_num_channels=self.params.NUM_CHANNELS,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "        return prepare_full_model_config\n",
    "\n",
    "    def get_prepare_lite_model_config(self) -> PrepareModelConfig:\n",
    "        config = self.config.prepare_models\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_lite_model_config = PrepareModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_path=Path(config.lite_model_path),\n",
    "            params_image_size=self.params.LITE_IMAGE_SIZE,\n",
    "            params_num_classes=self.params.NUM_CLASSES,\n",
    "            params_num_layers=self.params.LITE_NUM_LAYERS,\n",
    "            params_hidden_dim=self.params.LITE_HIDDEN_DIM,\n",
    "            params_mlp_dim=self.params.LITE_MLP_DIM,\n",
    "            params_num_heads=self.params.LITE_NUM_HEADS,\n",
    "            params_dropout_rate=self.params.DROPOUT_RATE,\n",
    "            params_num_patches=self.params.LITE_NUM_PATCHES,\n",
    "            params_patch_size=self.params.LITE_PATCH_SIZE,\n",
    "            params_num_channels=self.params.NUM_CHANNELS,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "        return prepare_lite_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-07 04:44:19,558: INFO: common: yaml file: params.yaml loaded successfully]\n"
     ]
    }
   ],
   "source": [
    "params = read_yaml(PARAMS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.LITE_NUM_PATCHES = (params.LITE_IMAGE_SIZE**2)//(params.LITE_PATCH_SIZE**2)\n",
    "params.FULL_NUM_PATCHES = (params.FULL_IMAGE_SIZE**2)//(params.FULL_PATCH_SIZE**2)\n",
    "\n",
    "params.LITE_FLAT_PATCHES_SHAPE = (params.LITE_NUM_PATCHES, params.LITE_PATCH_SIZE*params.LITE_PATCH_SIZE*params.NUM_CHANNELS)\n",
    "params.FULL_FLAT_PATCHES_SHAPE = (params.FULL_NUM_PATCHES, params.FULL_PATCH_SIZE*params.FULL_PATCH_SIZE*params.NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigBox({'LITE_IMAGE_SIZE': 256, 'LITE_NUM_LAYERS': 12, 'LITE_HIDDEN_DIM': 128, 'LITE_MLP_DIM': 32, 'LITE_NUM_HEADS': 6, 'LITE_PATCH_SIZE': 16, 'LITE_NUM_PATCHES': 256, 'LITE_FLAT_PATCHES_SHAPE': (256, 768), 'FULL_IMAGE_SIZE': 256, 'FULL_NUM_LAYERS': 12, 'FULL_HIDDEN_DIM': 768, 'FULL_MLP_DIM': 3072, 'FULL_NUM_HEADS': 12, 'FULL_PATCH_SIZE': 16, 'FULL_NUM_PATCHES': 256, 'FULL_FLAT_PATCHES_SHAPE': (256, 768), 'NUM_CLASSES': 11, 'DROPOUT_RATE': 0.1, 'NUM_CHANNELS': 3, 'LEARNING_RATE': 0.1, 'BATCH_SIZE': 16, 'NUM_EPOCHS': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareModel:\n",
    "    def __init__(self, config: PrepareModelConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def mlp(self, x):\n",
    "        x = L.Dense(self.config.params_mlp_dim, activation=\"gelu\")(x)\n",
    "        x = L.Dropout(self.config.params_dropout_rate)(x)\n",
    "        x = L.Dense(self.config.params_hidden_dim)(x)\n",
    "        x = L.Dropout(self.config.params_dropout_rate)(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def transformer_encoder(self, x):\n",
    "    \n",
    "        skip_1 = x\n",
    "        x = L.LayerNormalization()(x)\n",
    "        x = L.MultiHeadAttention(num_heads=self.config.params_num_heads, key_dim=self.config.params_hidden_dim)(x,x)\n",
    "        x = L.Add()([x, skip_1])\n",
    "        \n",
    "        skip_2 = x\n",
    "        x = L.LayerNormalization()(x)\n",
    "        x = self.mlp(x)\n",
    "        x = L.Add()([x, skip_2])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def conv_block(self, x, num_filters, kernel_size=3):\n",
    "        x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def deconv_block(self, x, num_filters):\n",
    "        x = L.Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=2)(x)\n",
    "        return x\n",
    "    \n",
    "    def get_full_model(self):\n",
    "        \"\"\" inputs \"\"\"\n",
    "    \n",
    "        input_shape = (self.config.params_num_patches, self.config.params_patch_size*self.config.params_patch_size*self.config.params_num_channels)\n",
    "        inputs = L.Input(input_shape)  ## (None, 256, 768)\n",
    "        \n",
    "        \"\"\" Patch + Positional Embeddings \"\"\"\n",
    "        patch_embed = L.Dense(self.config.params_hidden_dim)(inputs)  ## (None, 256, 768)\n",
    "        \n",
    "        positions = tf.range(start=0, limit=self.config.params_num_patches, delta=1) ## (256, )\n",
    "        \n",
    "        pos_embed = L.Embedding(input_dim=self.config.params_num_patches, output_dim=self.config.params_hidden_dim)(positions)  ## (256, 768)\n",
    "        \n",
    "        x = patch_embed + pos_embed\n",
    "        \n",
    "        skip_connection_indexes = [3, 6, 9, 12]\n",
    "        skip_connections = []\n",
    "        for i in range(1, self.config.params_num_layers +1, 1):\n",
    "            x = self.transformer_encoder(x)  ## (None, 256, 768)\n",
    "            \n",
    "            if i in skip_connection_indexes:\n",
    "                skip_connections.append(x)\n",
    "                \n",
    "        \"\"\" CNN Decoder  \"\"\"\n",
    "        \n",
    "        \n",
    "        z3, z6, z9, z12 = skip_connections\n",
    "        \n",
    "        size = self.config.params_image_size // self.config.params_patch_size\n",
    "        \n",
    "        \"\"\" Reshaping \"\"\"\n",
    "        z0 = L.Reshape((self.config.params_image_size, self.config.params_image_size, self.config.params_num_channels))(inputs)  ## (None, 256, 256, 3)\n",
    "        \n",
    "        z3 = L.Reshape((size, size, z3.shape[-1]))(z3)  ## (None, 16, 16, 768)\n",
    "        z6 = L.Reshape((size, size, z6.shape[-1]))(z6)  ## (None, 16, 16, 768)\n",
    "        z9 = L.Reshape((size, size, z9.shape[-1]))(z9)  ## (None, 16, 16, 768)\n",
    "        z12 = L.Reshape((size, size, z12.shape[-1]))(z12)  ## (None, 16, 16, 768)\n",
    "        \n",
    "        ## Decoder 1\n",
    "        x = self.deconv_block(z12, 512)\n",
    "        \n",
    "        s = self.deconv_block(z9, 512)\n",
    "        s = self.conv_block(s, 512)\n",
    "        \n",
    "        x = L.Concatenate()([x,s])\n",
    "        x = self.conv_block(x, 512)\n",
    "        x = self.conv_block(x, 512)\n",
    "        \n",
    "        ## Decoder 2\n",
    "        x = self.deconv_block(x, 256)\n",
    "        \n",
    "        s = self.deconv_block(z6, 256)\n",
    "        s = self.conv_block(s, 256)\n",
    "        s = self.deconv_block(s, 256)\n",
    "        s = self.conv_block(s, 256)\n",
    "        \n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 256)\n",
    "        x = self.conv_block(x, 256)\n",
    "        \n",
    "        ## Decoder 3\n",
    "        x = self.deconv_block(x, 128)\n",
    "        \n",
    "        s = self.deconv_block(z3, 128)\n",
    "        s = self.conv_block(s, 128)\n",
    "        s = self.deconv_block(s, 128)\n",
    "        s = self.conv_block(s, 128)\n",
    "        s = self.deconv_block(s, 128)\n",
    "        s = self.conv_block(s, 128)\n",
    "        \n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 128)\n",
    "        x = self.conv_block(x, 128)\n",
    "        \n",
    "        ## Decoder 4\n",
    "        x = self.deconv_block(x, 64)\n",
    "        \n",
    "        s = self.conv_block(z0, 64)\n",
    "        s = self.conv_block(s, 64)\n",
    "        \n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 64)\n",
    "        x = self.conv_block(x, 64)\n",
    "        \n",
    "        \"\"\" Output \"\"\"\n",
    "        outputs = L.Conv2D(self.config.params_num_classes, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x) ## 1 -> binary segmentation and hence the sigmoid fxn, can change for multi-class\n",
    "        full_model = Model(inputs, outputs, name=\"UNETR_2D\")\n",
    "        full_model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(self.config.params_learning_rate))\n",
    "        \n",
    "        \n",
    "        full_model.summary()\n",
    "        self.save_model(path=self.config.model_path, model=full_model)\n",
    "        \n",
    "        return full_model\n",
    "\n",
    "    def get_lite_model(self):\n",
    "        \"\"\" Inputs \"\"\"\n",
    "        input_shape = (self.config.params_num_patches, self.config.params_patch_size * self.config.params_patch_size * self.config.params_num_channels)\n",
    "        inputs = L.Input(input_shape) ## (None, 256, 3072)\n",
    "        # print(inputs.shape)\n",
    "\n",
    "        \"\"\" Patch + Position Embeddings \"\"\"\n",
    "        patch_embed = L.Dense(self.config.params_hidden_dim)(inputs) ## (None, 256, 768)\n",
    "\n",
    "        positions = tf.range(start=0, limit=self.config.params_num_patches, delta=1) ## (256,)\n",
    "        pos_embed = L.Embedding(input_dim=self.config.params_num_patches, output_dim=self.config.params_hidden_dim)(positions) ## (256, 768)\n",
    "        x = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "        \"\"\" Transformer Encoder \"\"\"\n",
    "        skip_connection_index = [3, 6, 9, 12]\n",
    "        skip_connections = []\n",
    "\n",
    "        for i in range(1, self.config.params_num_layers+1, 1):\n",
    "            x = self.transformer_encoder(x)\n",
    "\n",
    "            if i in skip_connection_index:\n",
    "                skip_connections.append(x)\n",
    "\n",
    "        \"\"\" CNN Decoder \"\"\"\n",
    "        z3, z6, z9, z12 = skip_connections\n",
    "\n",
    "        ## Reshaping\n",
    "        z0 = L.Reshape((self.config.params_image_size, self.config.params_image_size, self.config.params_num_channels))(inputs)\n",
    "\n",
    "        shape = (\n",
    "            self.config.params_image_size//self.config.params_patch_size,\n",
    "            self.config.params_image_size//self.config.params_patch_size,\n",
    "            self.config.params_hidden_dim\n",
    "        )\n",
    "        z3 = L.Reshape(shape)(z3)\n",
    "        z6 = L.Reshape(shape)(z6)\n",
    "        z9 = L.Reshape(shape)(z9)\n",
    "        z12 = L.Reshape(shape)(z12)\n",
    "\n",
    "        ## Additional layers for managing different patch sizes\n",
    "        total_upscale_factor = int(log2(self.config.params_patch_size))\n",
    "        upscale = total_upscale_factor - 4\n",
    "\n",
    "        if upscale >= 2: ## Patch size 16 or greater\n",
    "            z3 = self.deconv_block(z3, z3.shape[-1], strides=2**upscale)\n",
    "            z6 = self.deconv_block(z6, z6.shape[-1], strides=2**upscale)\n",
    "            z9 = self.deconv_block(z9, z9.shape[-1], strides=2**upscale)\n",
    "            z12 = self.deconv_block(z12, z12.shape[-1], strides=2**upscale)\n",
    "            # print(z3.shape, z6.shape, z9.shape, z12.shape)\n",
    "\n",
    "        if upscale < 0: ## Patch size less than 16\n",
    "            p = 2**abs(upscale)\n",
    "            z3 = L.MaxPool2D((p, p))(z3)\n",
    "            z6 = L.MaxPool2D((p, p))(z6)\n",
    "            z9 = L.MaxPool2D((p, p))(z9)\n",
    "            z12 = L.MaxPool2D((p, p))(z12)\n",
    "\n",
    "        ## Decoder 1\n",
    "        x = self.deconv_block(z12, 128)\n",
    "\n",
    "        s = self.deconv_block(z9, 128)\n",
    "        s = self.conv_block(s, 128)\n",
    "\n",
    "        x = L.Concatenate()([x, s])\n",
    "\n",
    "        x = self.conv_block(x, 128)\n",
    "        x = self.conv_block(x, 128)\n",
    "\n",
    "        ## Decoder 2\n",
    "        x = self.deconv_block(x, 64)\n",
    "\n",
    "        s = self.deconv_block(z6, 64)\n",
    "        s = self.conv_block(s, 64)\n",
    "        s = self.deconv_block(s, 64)\n",
    "        s = self.conv_block(s, 64)\n",
    "\n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 64)\n",
    "        x = self.conv_block(x, 64)\n",
    "\n",
    "        ## Decoder 3\n",
    "        x = self.deconv_block(x, 32)\n",
    "\n",
    "        s = self.deconv_block(z3, 32)\n",
    "        s = self.conv_block(s, 32)\n",
    "        s = self.deconv_block(s, 32)\n",
    "        s = self.conv_block(s, 32)\n",
    "        s = self.deconv_block(s, 32)\n",
    "        s = self.conv_block(s, 32)\n",
    "\n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 32)\n",
    "        x = self.conv_block(x, 32)\n",
    "\n",
    "        ## Decoder 4\n",
    "        x = self.deconv_block(x, 16)\n",
    "\n",
    "        s = self.conv_block(z0, 16)\n",
    "        s = self.conv_block(s, 16)\n",
    "\n",
    "        x = L.Concatenate()([x, s])\n",
    "        x = self.conv_block(x, 16)\n",
    "        x = self.conv_block(x, 16)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        outputs = L.Conv2D(self.config.params_num_classes, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "        lite_model = Model(inputs, outputs, name=\"UNETR_2D_lite\")\n",
    "        lite_model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(self.config.params_learning_rate))\n",
    "        \n",
    "        \n",
    "        lite_model.summary()\n",
    "        self.save_model(path=self.config.model_path, model=lite_model)\n",
    "        \n",
    "        return lite_model\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-07 04:48:59,486: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-07 04:48:59,496: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-07 04:48:59,497: INFO: common: created directory at: artifacts]\n",
      "<__main__.ConfigurationManager object at 0x000002503EEAC730>\n",
      "[2024-05-07 04:48:59,499: INFO: common: created directory at: artifacts/prepare_model]\n",
      "full  model already exists, skiping \n",
      "[2024-05-07 04:48:59,502: INFO: common: created directory at: artifacts/prepare_model]\n",
      "lite  model already exists, skiping \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    print(config)\n",
    "    prepare_full_model_config = config.get_prepare_full_model_config()\n",
    "    if not os.path.exists(prepare_full_model_config.model_path):\n",
    "        prepare_full_model = PrepareModel(config=prepare_full_model_config)\n",
    "        prepare_full_model.get_full_model()\n",
    "    else:\n",
    "        print(\"full  model already exists, skiping \")\n",
    "        \n",
    "    prepare_lite_model_config = config.get_prepare_lite_model_config()\n",
    "    if not os.path.exists(prepare_lite_model_config.model_path):\n",
    "        prepare_lite_model = PrepareModel(config=prepare_lite_model_config)\n",
    "        prepare_lite_model.get_lite_model()\n",
    "    else:\n",
    "        print(\"lite  model already exists, skiping \")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(\"artifacts/prepare_model/full_model.keras\"):\n",
    "    print(\"check\")\n",
    "else:\n",
    "    print(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_full_model_config.params_mlp_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
